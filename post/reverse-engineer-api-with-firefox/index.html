<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Reverse-engineering webapp APIs with Firefox - Jiby&#39;s selfhosted effort</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="Reverse-engineering webapp APIs with Firefox" />
<meta property="og:description" content="I&rsquo;m writing code to back up my user data off a website that lets me see all of my info (including querying by time, account etc) but doesn&rsquo;t have export features (officially). I am certain there&rsquo;s an API behind the site that I just have to make sense of.
Since the webapp is requesting data from the API when I click, we should be able to record the web traffic to explore the API." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jiby.tech/post/reverse-engineer-api-with-firefox/" />
<meta property="article:published_time" content="2019-10-09T00:00:00+01:00" />
<meta property="article:modified_time" content="2019-10-09T00:00:00+01:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Reverse-engineering webapp APIs with Firefox"/>
<meta name="twitter:description" content="I&rsquo;m writing code to back up my user data off a website that lets me see all of my info (including querying by time, account etc) but doesn&rsquo;t have export features (officially). I am certain there&rsquo;s an API behind the site that I just have to make sense of.
Since the webapp is requesting data from the API when I click, we should be able to record the web traffic to explore the API."/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" /><script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script><script src="/js/main.js"></script>
</head>

<body>
	<div class="container wrapper post">
		<div class="header">
	<h1 class="site-title">Jiby&#39;s selfhosted effort</h1>
	<div class="site-description"><h2>Jb Doyon&rsquo;s personal website</h2><nav class="nav social">
			<ul class="flat"><a href="https://github.com/OverkillGuy" title="Github"><i data-feather="github"></i></a><a href="https://www.linkedin.com/in/jbdoyon/" title="Linkedin"><i data-feather="linkedin"></i></a><a href="/index.xml" title="RSS"><i data-feather="rss"></i></a></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/post">All posts</a>
			</li>
			
			<li>
				<a href="/tags/presentation">Presentations</a>
			</li>
			
			<li>
				<a href="/about">About</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post-header">
			<h1 class="title">Reverse-engineering webapp APIs with Firefox</h1>
			<div class="meta">Posted on &mdash; Oct 9, 2019</div>
		</div>

		<div class="markdown">
			<p>I&rsquo;m writing code to back up my user data off a website that lets me
<span class="underline">see</span> all of my info (including querying by time, account etc) but
doesn&rsquo;t have export features (officially). I am certain there&rsquo;s an API
behind the site that I just have to make sense of.</p>

<p>Since the webapp is requesting data from the API when I click, we
should be able to record the web traffic to explore the API. My first
thought was to use <code>tcpdump(8)</code>, a powerful network sniffer. But for
HTTPS traffic, the TLS encryption makes the network-level capture
useless. We can of course look into <a href="https://mitmproxy.org/">MITM HTTPS proxies</a>. But it turns
out it can be even easier than that, as we can tell Firefox to record
this for us during normal website use. Let&rsquo;s see how Firefox can help
in reverse-engineering APIs!</p>

<p>Open the Firefox developer tools&rsquo; <a href="https://developer.mozilla.org/en-US/docs/Tools/Network%5FMonitor">Network Monitor</a>, and enable the
&ldquo;Persist logs&rdquo; setting, as we&rsquo;ll be crossing many subpages, and want
to keep the logs during all that browsing. Go through the login
process as usual, entering credentials when needed. Do the activities
you want to be able to reproduce through the API, making sure you
capture all the variations in calls like different query parameters
(such as date ranges for data graphs).</p>

<figure>
    <img src="https://mdn.mozillademos.org/files/16245/network%5Fmonitor.png"
         alt="Figure 1: Firefox network monitor example (credit: Mozilla docs)" width="100%"/> <figcaption>
            <p>Figure 1: Firefox network monitor example (credit: Mozilla docs)</p>
        </figcaption>
</figure>


<p>You now have a good view of that traffic in Firefox. That&rsquo;s enough to
get you going, reviewing the specific URLs, parameters, verbs. But
that&rsquo;s not the best part: Firefox can export this file for later use.
It&rsquo;s called <a href="https://w3c.github.io/web-performance/specs/HAR/Overview.html">HAR (Http ARchives)</a>, and is available through the menu on
the far right of the developer toolbar (see Figure <a href="#orgfcfdf9d">2</a>).</p>

<p><a id="orgfcfdf9d"></a></p>

<figure>
    <img src="/ox-hugo/har-save.png"
         alt="Figure 2: Save All as HAR menu in Firefox Network monitor"/> <figcaption>
            <p>Figure 2: Save All as HAR menu in Firefox Network monitor</p>
        </figcaption>
</figure>


<p>The magic is that HAR files are nothing but JSON files, which means we
can use our friend <a href="https://stedolan.github.io/jq/">jq(1)</a> to run analysis on our requests!</p>

<p>I can easily<sup class="footnote-ref" id="fnref:fn-1"><a href="#fn:fn-1">1</a></sup> get the path to
walk through the HAR file to generalize some <code>jq</code> query, letting unix
tools do the rest.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#008000"># show all the cookies used in requests</span>
<span style="color:#008000"># append `| sort | uniq -c | sort -r` to get usage count for each</span>
jq .log.entries[].request.cookies[] <span style="color:#a31515">&#34;api_recording.har&#34;</span>
<span style="color:#008000"># show all urls hit (filtering by domain, to skip CDNs)</span>
jq .log.entries[].request.url <span style="color:#a31515">&#34;api_recording.har&#34;</span> <span style="color:#a31515">\
</span><span style="color:#a31515"></span>  | grep $MY_DOMAIN | sort | uniq -c | sort -r</code></pre></div>
<div class="src-block-caption">
  <span class="src-block-number">Code Snippet 1</span>:
  A few interesting queries
</div>

<p>Here&rsquo;s what it looks like on a <a href="https://github.com/Sterlingg/json-snatcher">Github project</a>:</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">      5 github.com/Sterlingg/json-snatcher/show_partial
      4 github.com/Sterlingg/json-snatcher
      3 github.com/Sterlingg/json-snatcher/issues
      2 github.com/Sterlingg/json-snatcher/used_by_count
      2 github.com/Sterlingg/json-snatcher/pull/10/hovercard
      2 github.com/Sterlingg/json-snatcher/pull/10/files
      1 github.com/Sterlingg/json-snatcher/ref-list/master
      1 github.com/Sterlingg/json-snatcher/raw/master/Demo/demo.gif
      1 github.com/Sterlingg/json-snatcher/pulls
      1 github.com/Sterlingg/json-snatcher/pull/10/show_partial
      1 github.com/Sterlingg/json-snatcher/pull/10
      1 github.com/Sterlingg/json-snatcher/issues/9/hovercard
      1 github.com/Sterlingg/json-snatcher/issues/8/hovercard
      1 github.com/Sterlingg/json-snatcher/issues/8
      1 github.com/Sterlingg/json-snatcher/issues/11/hovercard
      1 github.com/Sterlingg/json-snatcher/issues/11
      1 github.com/Sterlingg/json-snatcher/issues/10
      1 github.com/Sterlingg/json-snatcher/contributors_size
      1 github.com/hovercards
      1 github.com/fluidicon.png</code></pre></div>
<p>The best part is to realize that since URLs are tree-structured, we
can actually view the URLs hit in tree form, which really helps
understand the structure of the site/API.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">jq .log.entries[].request.url <span style="color:#a31515">&#34;api_recording.har&#34;</span> <span style="color:#a31515">\
</span><span style="color:#a31515"></span>  | grep $MY_DOMAIN  | sed  <span style="color:#a31515">&#34;s;https://;;&#34;</span> | xargs mkdir -p
tree $MY_DOMAIN</code></pre></div>
<div class="src-block-caption">
  <span class="src-block-number">Code Snippet 2</span>:
  Get a (folder) tree view of URLs hit
</div>

<figure>
    <img src="/ox-hugo/github-url-tree.png"
         alt="Figure 3: A Github project&amp;rsquo;s URL tree using a (processed) Firefox network capture"/> <figcaption>
            <p>Figure 3: A Github project&rsquo;s URL tree using a (processed) Firefox network capture</p>
        </figcaption>
</figure>


<p>Seeing the tree is super helpful to figure out API structure. And
there we have it: Using Firefox to capture HTTPS traffic for API
reverse-engineering. No invasive debugging tools needed and our
standard unix tools are able to dissect this trove of data!</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:fn-1">Using <a href="https://github.com/Sterlingg/json-snatcher">Emacs plugin json-snatcher</a>
 <a class="footnote-return" href="#fnref:fn-1"><sup>[return]</sup></a></li>
</ol>
</div>

		</div>

	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div><a href="https://github.com/vividvilla/ezhil">Ezhil</a> theme <a href="https://github.com/OverkillGuy/ezhil">fork</a> | Built with <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div><script>feather.replace()</script>
</body>
</html>
